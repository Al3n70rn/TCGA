{
 "metadata": {
  "name": "",
  "signature": "sha256:6c4dcac7c4c2556debcb311dac6c084e518fdaa25363c7f0e0a90ceb91e51ea0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Process HNSCC Targeted Mutation Calls"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we are reading in variant calls for our molecular validation cohort. This script is still a little dirty... aka hard paths and the like.  The rest of the analysis can be picked up from the MAF file that we generate here, but if you are actually trying to run this part of the analysis please contact me.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../src/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/cellar/users/agross/TCGA_Code/TCGA/src\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Processing.Imports import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PATH = '/cellar/data/TCGA/protected/exome_andy/hnsc_targeted/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Read in Variant Calls"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read in all of the VCF files and pull out the SNVs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pts_snv = [f[:12] for f in os.listdir(PATH) if 'call_stats' in f and '~' not in f]\n",
      "vcf = pd.concat({p: pd.read_table(PATH + '{}_call_stats.txt'.format(p), skiprows=[0]) \n",
      "                 for p in pts_snv})\n",
      "vcf = vcf.reset_index()\n",
      "vcf = vcf.rename(columns={'level_0':'barcode'})\n",
      "vcf['barcode'] = vcf['barcode'].map(lambda s: s.replace('_','-'))\n",
      "pts_snv = map(lambda p: p.replace('_','-'), pts_snv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MuTect sometimes likes to fail ungracefully.  We can tell this when we see no variants in the last few genes.  Here I check for this and filter out those patients."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tab = vcf.groupby(['tumor_name','contig']).size().unstack()\n",
      "drop = tab[[19,20,22]].isnull().sum(1).order() == 3\n",
      "drop = [p[:12] for p,v in drop.iteritems() if v == True]\n",
      "pts_snv = [p for p in pts_snv if p not in drop]\n",
      "vcf = vcf[vcf.judgement == 'KEEP']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read in all of the indel calls.  I have this funky try catch because some of the files have the VCF header but no actual calls, Pandas does not like this.  For this reason I keep track of the patients with the pts_indels dict and the indel calls with the indels dict, and then put it all together."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indels = {}\n",
      "pts_indels = {}\n",
      "for f in os.listdir(PATH):\n",
      "    if not f.endswith('indels.txt'):\n",
      "        continue\n",
      "    pts_indels[f] = '-'.join(f.split('_')[:3])\n",
      "    try:\n",
      "        indels[pts_indels[f]] = pd.read_table(PATH + f, skiprows=102, header=None)\n",
      "    except:\n",
      "        pass\n",
      "pts_indels = pd.Series(pts_indels)\n",
      "indels = pd.concat(indels)\n",
      "indels.index.names = ['barcode','num']\n",
      "indels.columns = ['chromosome','pos','id','ref','alt','qual','filter','info',\n",
      "                  'format','tumor','normal']\n",
      "indels = indels.reset_index(0)\n",
      "indels = indels[indels['info'] == 'SOMATIC']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not all variant calling runs were sucessfull.  Here we are only using patients with a sucessfull SomaticIndelDetector run and a sucessfull MuTect run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pts = list(set(pts_indels).intersection(set(pts_snv)))\n",
      "len(pts), len(pts_indels), len(pts_snv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(462, 463, 462)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Annotate the Variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* I have not found a good automated way to do this, and the best solution is to upload the variants to the [Oncotator web site](http://www.broadinstitute.org/oncotator/)\n",
      "* They do have a REST API but it annotates about 2 variants per second, which takes a while with this many samples\n",
      "* The solution that I have emerged on it to save the variants to a temporar file in the format that Oncotator likes, upload that file to the website, and read in the oncotator output back into the program.  \n",
      "* Yes, this is far from elegant, but works for now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def format_indels_for_oncotator(s):\n",
      "    r = {}\n",
      "    r['chr'] = s['chromosome']\n",
      "    r['start'] = s['pos']\n",
      "    r['end'] = int(s['pos']) + len(s['ref']) - 1\n",
      "    r['reference_allele'] = s['ref']\n",
      "    r['observed_allele'] = s['alt']\n",
      "    return pd.Series(r)\n",
      "\n",
      "def format_snvs_for_oncotator(s):\n",
      "    r = {}\n",
      "    r['chr'] = s['contig']\n",
      "    r['start'] = s['position']\n",
      "    r['end'] = s['position']\n",
      "    r['reference_allele'] = s['ref_allele']\n",
      "    r['observed_allele'] = s['alt_allele']\n",
      "    r = pd.Series(r)\n",
      "    return r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "onc_indel = indels.set_index('barcode').apply(format_indels_for_oncotator,1)\n",
      "onc_vcf = vcf.set_index('barcode').apply(format_snvs_for_oncotator, 1)\n",
      "onc = pd.concat([onc_indel, onc_vcf])\n",
      "onc = onc.reset_index('barcode')\n",
      "onc = onc[['chr', 'start', 'end', 'reference_allele', 'observed_allele']]\n",
      "onc.to_csv('tmp.txt', sep=' ', index=False, header=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yes this is a hard path.  If you are trying to replicate this, replace this with the downloaded oncotator file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ONCOTATOR_FILE = '/cellar/users/agross/Downloads/oncotator_output (5).txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Oncotator only outputs annotations for unique variants. So I have to create a lookup for each mutation and then map it across the whole dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tab = pd.read_table(ONCOTATOR_FILE, skiprows=[0])\n",
      "tt = tab[['Chromosome','Start_position','End_position','Reference_Allele', 'Tumor_Seq_Allele1']]\n",
      "tt = pd.Series({i: tuple(v) for i,v in tt.iterrows()})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "onc_indel = indels.set_index('barcode').apply(format_indels_for_oncotator,1)\n",
      "onc_vcf = vcf.set_index('barcode').apply(format_snvs_for_oncotator, 1)\n",
      "onc = pd.concat([onc_indel, onc_vcf])\n",
      "oo = onc[['chr','start','end','reference_allele','observed_allele']]\n",
      "oo = [tuple(v) for i,v in oo.iterrows()]\n",
      "maf = pd.DataFrame(tab.ix[tt[tt == s].index[0]] for s in oo)\n",
      "maf.index = onc.index\n",
      "maf = maf.set_index('Hugo_Symbol', append=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here I am turning the MAF file into a gene by patient mutation matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keep = (maf.Variant_Classification.isin(['Silent', 'Intron', \"3'UTR\", \"5'UTR\"])==False)\n",
      "mat = keep.groupby(level=[0,1]).sum()\n",
      "mat = mat.unstack().ix[pts].fillna(0).T\n",
      "(mat > 0).sum(1).order()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "Hugo_Symbol\n",
        "GRB2             0\n",
        "MAPK3            0\n",
        "SNAPC5           0\n",
        "KRAS             1\n",
        "NRAS             1\n",
        "YWHAB            2\n",
        "RAF1             3\n",
        "IRS1             4\n",
        "MAP2K1           6\n",
        "MAP2K2           6\n",
        "MAPK1            7\n",
        "SOS1             8\n",
        "IRS2             9\n",
        "EGFR            14\n",
        "HRAS            28\n",
        "ASPM            29\n",
        "CASP8           47\n",
        "MUC5B           48\n",
        "TP53           307\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save the MAF file and the gene by patient for later analysis.  This is not a proper MAF file as I append the patients with variant calls, but wildtype TP53 to the end of the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wildtype = set(pts) - set(maf.index.get_level_values('barcode'))\n",
      "wildtype = pd.Series({(p, 'wildtype'):nan for p in wildtype})\n",
      "wildtype.index = pd.MultiIndex.from_tuples(wildtype.index)\n",
      "wildtype = pd.DataFrame({'Entrez_Gene_Id': wildtype})\n",
      "maf_wt = maf.append(wildtype)[maf.columns]\n",
      "maf_wt = maf_wt.dropna(axis=1, how='all')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maf_wt.to_csv('../Extra_Data/HNSCC_molecular_validation.maf', sep='\\t')\n",
      "mat.to_csv('../Extra_Data/HNSCC_molecular_validation_matrix.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}